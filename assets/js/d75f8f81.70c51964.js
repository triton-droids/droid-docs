"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[522],{8475:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var i=t(4848),o=t(8453);const s={sidebar_position:1,title:"ROS2",hide_title:!0},a=void 0,r={id:"software/onboarding/ros2",title:"ROS2",description:"This tutorial is generously provided by Dr Ilkka Jormanainen at the University of Eastern Finland and Henki Robotics. For up to date material, please reference the official source repository available here.",source:"@site/docs/software/onboarding/ros2.md",sourceDirName:"software/onboarding",slug:"/software/onboarding/ros2",permalink:"/droid-docs/software/onboarding/ros2",draft:!1,unlisted:!1,editUrl:"https://github.com/triton-droids/droid-docs/tree/main/docs/software/onboarding/ros2.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,title:"ROS2",hide_title:!0},sidebar:"docsSidebar",previous:{title:"Software Title",permalink:"/droid-docs/software/"},next:{title:"Controls Title",permalink:"/droid-docs/controls/"}},l={},d=[{value:"Re-build a container",id:"re-build-a-container",level:4},{value:"Run a container",id:"run-a-container",level:4},{value:"Run a container in detached mode",id:"run-a-container-in-detached-mode",level:4},{value:"Open a new terminal inside the Docker container <a></a>",id:"open-a-new-terminal-inside-the-docker-container-",level:4},{value:"List all running Docker containers",id:"list-all-running-docker-containers",level:4},{value:"Stop a running container",id:"stop-a-running-container",level:4},{value:"Remove a container",id:"remove-a-container",level:4},{value:"Setup",id:"setup",level:2},{value:"What You&#39;ll Learn",id:"what-youll-learn",level:4},{value:"Prerequisites",id:"prerequisites",level:4},{value:"Installing Docker",id:"installing-docker",level:3},{value:"System Requirements",id:"system-requirements",level:4},{value:"1. Enable WSL 2",id:"1-enable-wsl-2",level:4},{value:"2. Download Docker Desktop",id:"2-download-docker-desktop",level:4},{value:"3. Verify Installation",id:"3-verify-installation",level:4},{value:"1. Add Docker&#39;s Official GPG Key",id:"1-add-dockers-official-gpg-key",level:4},{value:"2. Set Up the Docker Repository",id:"2-set-up-the-docker-repository",level:4},{value:"3. Install Docker Engine and packages",id:"3-install-docker-engine-and-packages",level:4},{value:"4. Verify Installation",id:"4-verify-installation",level:4},{value:"Optional: Admin Privileges",id:"optional-admin-privileges",level:4},{value:"Optional: NVIDIA GPU Support with Docker",id:"optional-nvidia-gpu-support-with-docker",level:4},{value:"1. Configure the production repository:",id:"1-configure-the-production-repository",level:4},{value:"2. (Optional) Enable experimental packages:",id:"2-optional-enable-experimental-packages",level:4},{value:"3. Update and install:",id:"3-update-and-install",level:4},{value:"4. Configure Docker to use NVIDIA runtime:",id:"4-configure-docker-to-use-nvidia-runtime",level:4},{value:"5. Restart Docker:",id:"5-restart-docker",level:4},{value:"Installing Content Material",id:"installing-content-material",level:3},{value:"Create Your Workspace",id:"create-your-workspace",level:4},{value:"Launch the Docker Container",id:"launch-the-docker-container",level:4},{value:"Open a Terminal Inside the Container",id:"open-a-terminal-inside-the-container",level:4},{value:"Run the Simulation",id:"run-the-simulation",level:4},{value:"ROS 2 Introduction",id:"ros-2-introduction",level:2},{value:"What You&#39;ll Learn",id:"what-youll-learn-1",level:4},{value:"Conceptual Understanding",id:"conceptual-understanding",level:3},{value:"Gazebo",id:"gazebo",level:4},{value:"Rviz",id:"rviz",level:4},{value:"Andino",id:"andino",level:4},{value:"Launch the Andino Robot in Gazebo Simulation",id:"launch-the-andino-robot-in-gazebo-simulation",level:3},{value:"Exercise 1. Controlling the Robot",id:"exercise-1-controlling-the-robot",level:4},{value:"ROS2 Topics",id:"ros2-topics",level:3},{value:"Subscribing to a Topic",id:"subscribing-to-a-topic",level:4},{value:"Publishing to a Topic",id:"publishing-to-a-topic",level:4},{value:"Move The Robot via CLI Topic",id:"move-the-robot-via-cli-topic",level:5},{value:"Exercise 2. Publish a Robot to Rotate",id:"exercise-2-publish-a-robot-to-rotate",level:4},{value:"RViz",id:"rviz-1",level:3},{value:"Subscribe to a new data source:",id:"subscribe-to-a-new-data-source",level:4},{value:"Transformation Frames (TFs)",id:"transformation-frames-tfs",level:3},{value:"Commonly Used Coordinate Frames",id:"commonly-used-coordinate-frames",level:4},{value:"TFs in RViz",id:"tfs-in-rviz",level:3},{value:"Changing Fixed Frame",id:"changing-fixed-frame",level:4},{value:"Visualizing the TF-tree",id:"visualizing-the-tf-tree",level:4},{value:"SLAM &amp; Navigation Demo",id:"slam--navigation-demo",level:2},{value:"What You&#39;ll Learn",id:"what-youll-learn-2",level:4},{value:"Basic Concepts",id:"basic-concepts",level:3},{value:"SLAM-toolbox",id:"slam-toolbox",level:4},{value:"Nav2",id:"nav2",level:4},{value:"AMCL",id:"amcl",level:4},{value:"Mapping Demo",id:"mapping-demo",level:3},{value:"Autonomous Navigation",id:"autonomous-navigation",level:3},{value:"Exercise 3. Autonomous Navigation with Nav2",id:"exercise-3-autonomous-navigation-with-nav2",level:4},{value:"ROS2 Services",id:"ros2-services",level:3},{value:"Create Your First ROS 2 Package",id:"create-your-first-ros-2-package",level:2},{value:"What You&#39;ll Learn",id:"what-youll-learn-3",level:4},{value:"Creating a ROS2 Package",id:"creating-a-ros2-package",level:3},{value:"Building and Sourcing a Package",id:"building-and-sourcing-a-package",level:3},{value:"Details of ROS2 Package",id:"details-of-ros2-package",level:3},{value:"ros2_exercises",id:"ros2_exercises",level:4},{value:"ros2_exercises/odometry_publisher.py",id:"ros2_exercisesodometry_publisherpy",level:4},{value:"setup.py",id:"setuppy",level:4},{value:"packages.xml",id:"packagesxml",level:4},{value:"Running the Package",id:"running-the-package",level:4},{value:"Robot Odometry",id:"robot-odometry",level:2},{value:"What You&#39;ll Learn",id:"what-youll-learn-4",level:4},{value:"Common Types of Odometry Data",id:"common-types-of-odometry-data",level:3},{value:"Exercise: Calculate Odometry from Wheel Encoders",id:"exercise-calculate-odometry-from-wheel-encoders",level:3},{value:"Testing the Odometry",id:"testing-the-odometry",level:3},{value:"Your Task",id:"your-task",level:4},{value:"Visualizing the Driven Path",id:"visualizing-the-driven-path",level:3},{value:"Test the Odometry",id:"test-the-odometry",level:3},{value:"Path Planning",id:"path-planning",level:2},{value:"What You&#39;ll Learn",id:"what-youll-learn-5",level:4},{value:"Basic Concepts",id:"basic-concepts-1",level:3},{value:"Static Map",id:"static-map",level:4},{value:"Global Costmap",id:"global-costmap",level:4},{value:"Local Costmap",id:"local-costmap",level:4},{value:"Path Planner",id:"path-planner",level:4},{value:"Controller",id:"controller",level:4},{value:"Behavior Trees",id:"behavior-trees",level:4},{value:"Building our Path Planner",id:"building-our-path-planner",level:3},{value:"Straight Line Planner",id:"straight-line-planner",level:4},{value:"Change the Planner",id:"change-the-planner",level:4},{value:"Verify the planner has changed",id:"verify-the-planner-has-changed",level:4},{value:"Interestingly, few seconds after sending the goal, you will notice that your robot will start moving a little. Why is that?",id:"interestingly-few-seconds-after-sending-the-goal-you-will-notice-that-your-robot-will-start-moving-a-little-why-is-that",level:5},{value:"Creating Straight Line Planner",id:"creating-straight-line-planner",level:3},{value:"Implementation of Straight Line Planner",id:"implementation-of-straight-line-planner",level:4},{value:"Your Task",id:"your-task-1",level:4}];function c(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",h5:"h5",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["This tutorial is generously provided by Dr Ilkka Jormanainen at the University of Eastern Finland and Henki Robotics. For up to date material, please reference the official source repository available ",(0,i.jsx)(n.a,{href:"https://github.com/triton-droids/ros2_onboarding/tree/main",children:"here"}),"."]})}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:(0,i.jsx)("strong",{children:"Docker Cheatsheet"})}),(0,i.jsx)(n.p,{children:"List of all the used Docker commands during the exercises."}),(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note:"})," ",(0,i.jsx)(n.code,{children:"docker compose"})," commands must be run in the directory that contains the ",(0,i.jsx)(n.code,{children:"docker-compose.yaml"})," file:"]}),"\n"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd robotics_essentials_ros2/docker/\n"})}),(0,i.jsx)(n.hr,{}),(0,i.jsx)(n.h4,{id:"re-build-a-container",children:"Re-build a container"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker compose up --build\n"})}),(0,i.jsx)(n.hr,{}),(0,i.jsx)(n.h4,{id:"run-a-container",children:"Run a container"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker compose up\n"})}),(0,i.jsx)(n.hr,{}),(0,i.jsx)(n.h4,{id:"run-a-container-in-detached-mode",children:"Run a container in detached mode"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker compose up -d\n"})}),(0,i.jsx)(n.hr,{}),(0,i.jsxs)(n.h4,{id:"open-a-new-terminal-inside-the-docker-container-",children:["Open a new terminal inside the Docker container ",(0,i.jsx)("a",{id:"new-terminal"})]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker exec -it robotics_essentials_ros2 bash\n"})}),(0,i.jsx)(n.hr,{}),(0,i.jsx)(n.h4,{id:"list-all-running-docker-containers",children:"List all running Docker containers"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker ps\n"})}),(0,i.jsx)(n.hr,{}),(0,i.jsx)(n.h4,{id:"stop-a-running-container",children:"Stop a running container"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker stop robotics_essentials_ros2\n"})}),(0,i.jsx)(n.hr,{}),(0,i.jsx)(n.h4,{id:"remove-a-container",children:"Remove a container"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker rm robotics_essentials_ros2\n"})})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,i.jsx)(n.p,{children:"Set up your development environment, launch your first Gazebo simulation, and get familiar with using Docker containers for ROS2."}),"\n",(0,i.jsx)(n.h4,{id:"what-youll-learn",children:"What You'll Learn"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Setup the exercises"}),"\n",(0,i.jsx)(n.li,{children:"Run the Gazebo simulation"}),"\n",(0,i.jsx)(n.li,{children:"Learn to use Docker"}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"x86_64 CPU architecture, (ARM64/AArch64 will not work)"}),"\n",(0,i.jsx)(n.li,{children:"Docker"}),"\n",(0,i.jsx)(n.li,{children:"Git"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"installing-docker",children:"Installing Docker"}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:(0,i.jsx)("strong",{children:"Windows (Docker Desktop)"})}),(0,i.jsx)(n.h4,{id:"system-requirements",children:"System Requirements"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Windows 10 64-bit: Pro, Enterprise, or Education (build 19044+)"}),"\n",(0,i.jsx)(n.li,{children:"Windows 11 64-bit (any edition)"}),"\n",(0,i.jsx)(n.li,{children:"WSL 2 must be enabled (required for Windows Home)"}),"\n"]}),(0,i.jsx)(n.hr,{}),(0,i.jsx)(n.h4,{id:"1-enable-wsl-2",children:"1. Enable WSL 2"}),(0,i.jsxs)(n.p,{children:["Open ",(0,i.jsx)(n.strong,{children:"PowerShell as Administrator"})," and run:"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-powershell",children:"wsl --install\n"})}),(0,i.jsxs)(n.p,{children:["Then ",(0,i.jsx)(n.strong,{children:"restart your computer"}),"."]}),(0,i.jsx)(n.p,{children:"Alternatively, enable it manually:"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Open Control Panel \u2192 Programs \u2192 Turn Windows features on or off"}),"\n",(0,i.jsxs)(n.li,{children:["Enable:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Virtual Machine Platform"}),"\n",(0,i.jsx)(n.li,{children:"Windows Subsystem for Linux"}),"\n"]}),"\n"]}),"\n"]}),(0,i.jsx)(n.h4,{id:"2-download-docker-desktop",children:"2. Download Docker Desktop"}),(0,i.jsxs)(n.p,{children:["Visit the official Docker Desktop page:",(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.a,{href:"https://www.docker.com/products/docker-desktop/",children:"https://www.docker.com/products/docker-desktop/"})]}),(0,i.jsxs)(n.p,{children:["Click ",(0,i.jsx)(n.strong,{children:"\u201cDownload for Windows\u201d"})," and run the installer."]}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Select \u201cUse WSL 2 instead of Hyper-V\u201d"}),"\n",(0,i.jsxs)(n.li,{children:["Finish the setup and ",(0,i.jsx)(n.strong,{children:"reboot"})," if prompted"]}),"\n"]}),(0,i.jsx)(n.h4,{id:"3-verify-installation",children:"3. Verify Installation"}),(0,i.jsxs)(n.p,{children:["After rebooting, open ",(0,i.jsx)(n.strong,{children:"Docker Desktop"})," and confirm it is running."]}),(0,i.jsx)(n.p,{children:"Then open PowerShell and run:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-powershell",children:"docker --version\ndocker run hello-world\n"})}),(0,i.jsx)(n.p,{children:'You should see Docker version info and a "Hello from Docker!" message.'})]}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:(0,i.jsx)("strong",{children:"Ubuntu"})}),(0,i.jsx)(n.h4,{id:"1-add-dockers-official-gpg-key",children:"1. Add Docker's Official GPG Key"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n"})}),(0,i.jsx)(n.h4,{id:"2-set-up-the-docker-repository",children:"2. Set Up the Docker Repository"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'echo \\\n"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n$(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \\\nsudo tee /etc/apt/sources.list.d/docker.list > /dev/null\nsudo apt-get update\n'})}),(0,i.jsx)(n.h4,{id:"3-install-docker-engine-and-packages",children:"3. Install Docker Engine and packages"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n"})}),(0,i.jsx)(n.h4,{id:"4-verify-installation",children:"4. Verify Installation"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo docker --version\nsudo docker run hello-world\n"})}),(0,i.jsx)(n.p,{children:'You should see Docker version info and a "Hello from Docker!" confirmation message.'}),(0,i.jsx)(n.h4,{id:"optional-admin-privileges",children:"Optional: Admin Privileges"}),(0,i.jsxs)(n.p,{children:["You can allow your user to run Docker commands without needing ",(0,i.jsx)(n.code,{children:"sudo"}),":"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Create the Docker group\nsudo groupadd docker\n\n# Add your user to the group\nsudo usermod -aG docker $USER\n\n# Activate the new group (choose one)\nnewgrp docker  # OR log out and log back in\n"})}),(0,i.jsx)(n.p,{children:"Now test:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker run hello-world\n"})}),(0,i.jsx)(n.h4,{id:"optional-nvidia-gpu-support-with-docker",children:"Optional: NVIDIA GPU Support with Docker"}),(0,i.jsxs)(n.p,{children:["If you have an ",(0,i.jsx)(n.strong,{children:"NVIDIA GPU"})," and want GPU acceleration inside containers:"]}),(0,i.jsx)(n.h4,{id:"1-configure-the-production-repository",children:"1. Configure the production repository:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n&& curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\nsed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\nsudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n"})}),(0,i.jsx)(n.h4,{id:"2-optional-enable-experimental-packages",children:"2. (Optional) Enable experimental packages:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo sed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.list\n"})}),(0,i.jsx)(n.h4,{id:"3-update-and-install",children:"3. Update and install:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\n"})}),(0,i.jsx)(n.h4,{id:"4-configure-docker-to-use-nvidia-runtime",children:"4. Configure Docker to use NVIDIA runtime:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo nvidia-ctk runtime configure --runtime=docker\n"})}),(0,i.jsx)(n.h4,{id:"5-restart-docker",children:"5. Restart Docker:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo systemctl restart docker\n"})}),(0,i.jsx)(n.p,{children:"You're now ready to run GPU-accelerated containers with Docker!"})]}),"\n",(0,i.jsxs)(n.admonition,{type:"note",children:[(0,i.jsx)(n.p,{children:"All steps afterwards requires a terminal. If you are on windows, it will be easier using a WSL2 machine as the commands differ on Linux and Windows."}),(0,i.jsx)(n.p,{children:"To create a WSL2 machine, please open up powershell as admin and run the command below to enter an Ubuntu machine."}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"wsl -d ubuntu\n"})}),(0,i.jsx)(n.p,{children:"That powershell terminal is now running an Ubuntu machine and is how you will interact with it."})]}),"\n",(0,i.jsx)(n.h3,{id:"installing-content-material",children:"Installing Content Material"}),"\n",(0,i.jsx)(n.p,{children:"Clone the ROS2 onboarding repository:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/henki-robotics/robotics_essentials_ros2.git\n"})}),"\n",(0,i.jsx)(n.h4,{id:"create-your-workspace",children:"Create Your Workspace"}),"\n",(0,i.jsx)(n.p,{children:"Create a new workspace where you\u2019ll store your exercises. This directory will be automatically mounted inside the Docker container:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir -p $HOME/exercises_ws/src\n"})}),"\n",(0,i.jsx)(n.h4,{id:"launch-the-docker-container",children:"Launch the Docker Container"}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:(0,i.jsx)("strong",{children:"Only for Ubuntu Graphics"})}),(0,i.jsx)(n.p,{children:"Before starting the Docker container, allow X11 display access by running:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"xhost +\n"})}),(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note:"})," You must run this command every time you reboot your computer."]}),"\n"]})]}),"\n",(0,i.jsx)(n.p,{children:"Navigate to the Docker setup directory and launch the container:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd robotics_essentials_ros2/docker/\ndocker compose up\n"})}),"\n",(0,i.jsx)(n.p,{children:"This will build and launch the Docker container, which includes:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ubuntu base system"}),"\n",(0,i.jsx)(n.li,{children:"ROS 2"}),"\n",(0,i.jsx)(n.li,{children:"Gazebo"}),"\n",(0,i.jsx)(n.li,{children:"Simulated Andino robot environment"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Wait for the container to start up completely."}),"\n",(0,i.jsx)(n.h4,{id:"open-a-terminal-inside-the-container",children:"Open a Terminal Inside the Container"}),"\n",(0,i.jsx)(n.p,{children:"Once the container is running, open a new terminal on your host system, then start a terminal session inside the Docker container using the command below:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker exec -it robotics_essentials_ros2 bash\n"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"docker compose up"})," command launches a fully isolated virtual environment.\nThe ",(0,i.jsx)(n.code,{children:"docker exec"})," command lets you interact with the container from a terminal."]}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{type:"danger",children:(0,i.jsx)(n.p,{children:"For windows users, this might be highly confusing. For high level understanding, you have your base machine (Windows), that has a WSL2 Machine (ubuntu) inside of it. This WSL2 machine (ubuntu) will then create another machine inside of it."})}),"\n",(0,i.jsx)(n.h4,{id:"run-the-simulation",children:"Run the Simulation"}),"\n",(0,i.jsx)(n.p,{children:"Inside the Docker container, verify the setup by launching the Andino simulation:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch andino_gz andino_gz.launch.py\n"})}),"\n",(0,i.jsx)(n.p,{children:"If Gazebo does not open after a few minutes:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ensure you have a good internet connection \u2014 Gazebo may download assets on the first launch."}),"\n",(0,i.jsxs)(n.li,{children:["You may see repeated ",(0,i.jsx)(n.code,{children:"[ros_gz_sim]: Requesting list of world names"})," logs \u2014 this is normal."]}),"\n",(0,i.jsx)(n.li,{children:"If Gazebo appears frozen, press \u201cWait\u201d when prompted."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"If the problem persists:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Refer to ",(0,i.jsx)(n.a,{href:"https://github.com/gazebosim/gz-sim/issues/38",children:"Gazebo GitHub Issue #38"})]}),"\n",(0,i.jsx)(n.li,{children:"Run the following command to temporarily disable your firewall:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo ufw disable\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Once Gazebo opens, press the ",(0,i.jsx)(n.strong,{children:"play"})," button to start the simulation."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/images/andino_sim_screenshot.png",alt:""})}),"\n",(0,i.jsx)(n.p,{children:"You\u2019ve now successfully:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Installed all the required tools using Docker"}),"\n",(0,i.jsx)(n.li,{children:"Started your first simulation with Gazebo"}),"\n",(0,i.jsx)(n.li,{children:"Prepared your environment for the upcoming exercises"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"ros-2-introduction",children:"ROS 2 Introduction"}),"\n",(0,i.jsx)(n.p,{children:"Get introduced to ROS 2 fundamentals, work with Gazebo and RViz, and learn how to use topics and transformations (TF)."}),"\n",(0,i.jsx)(n.h4,{id:"what-youll-learn-1",children:"What You'll Learn"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"What are ROS2, Gazebo, and RViz"}),"\n",(0,i.jsx)(n.li,{children:"How to launch Andino Sim and Control it from Gazebo"}),"\n",(0,i.jsx)(n.li,{children:"ROS2 Topics"}),"\n",(0,i.jsx)(n.li,{children:"TF Frames"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"What are ROS 2, Gazebo, and Rviz\nHow to launch Andino simulation and control the robot from Gazebo\nWhat ROS 2 topics are\nHow to publish to a topic\nHow to subscribe to a topic\nWhat tf-frames are"}),"\n",(0,i.jsx)(n.h3,{id:"conceptual-understanding",children:"Conceptual Understanding"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/ros_logo_white_bg.svg",alt:""})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://www.ros.org/",children:"ROS 2 (Robot Operating System 2)"})," is an open-source framework for building robot software.\nIt provides a set of tools, libraries, and conventions, including a middleware for internal communication.\nIt is designed to support real-time performance and multi-robot systems."]}),"\n",(0,i.jsx)(n.h4,{id:"gazebo",children:"Gazebo"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/gazebo_logo_white_bg.svg",alt:""})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://gazebosim.org/home",children:"Gazebo"})," is a powerful open-source robotics simulator that allows developers to test and validate robot designs in complex environments, offering realistic physics and sensor models."]}),"\n",(0,i.jsx)(n.h4,{id:"rviz",children:"Rviz"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/rviz_logo.png",alt:""})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://github.com/ros2/rviz",children:"RViz"})," is a 3D visualization tool for ROS that enables developers to visualize sensor data, robot models, and environment maps, aiding in debugging and monitoring robot behavior."]}),"\n",(0,i.jsx)(n.h4,{id:"andino",children:"Andino"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/andino_robot.png",alt:""})}),"\n",(0,i.jsxs)(n.p,{children:["Andino is a fully open-source, educational low-cost robot developed by ",(0,i.jsx)(n.a,{href:"https://github.com/Ekumen-OS/andino",children:"Ekumen"}),".\nIt uses ROS 2 to implement its functionalities and has fully functional ",(0,i.jsx)(n.a,{href:"https://github.com/Ekumen-OS/andino_gz",children:"Gazebo simulations"})," of it available."]}),"\n",(0,i.jsx)(n.h3,{id:"launch-the-andino-robot-in-gazebo-simulation",children:"Launch the Andino Robot in Gazebo Simulation"}),"\n",(0,i.jsx)(n.p,{children:"From the setup, we can run these commands if you haven't yet:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd robotics_essentials_ros2/docker/\ndocker compose up -d\ndocker exec -it robotics_essentials_ros2 bash\nros2 launch andino_gz andino_gz.launch.py\n"})}),"\n",(0,i.jsx)(n.h4,{id:"exercise-1-controlling-the-robot",children:"Exercise 1. Controlling the Robot"}),"\n",(0,i.jsx)(n.p,{children:"Using the GUI, try out all the teleoperation commands to control the Andino. During startup, the Gazebo simulation will most likely be paused. Just make sure you press first the play button in the bottom left of the Gazebo UI to start the simulation and see that the robot moves when you send teleoperation commands."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/gazebo_teleop.png",alt:""})}),"\n",(0,i.jsx)(n.h3,{id:"ros2-topics",children:"ROS2 Topics"}),"\n",(0,i.jsx)(n.p,{children:"ROS 2 topics are a core communication mechanism in ROS 2 that enable data exchange in a publish/subscribe model. Publishers send messages to a named topic, while subscribers listen to that topic to receive relevant data."}),"\n",(0,i.jsx)(n.h4,{id:"subscribing-to-a-topic",children:"Subscribing to a Topic"}),"\n",(0,i.jsx)(n.p,{children:"By subscribing to a topic, you can read sensor data (lidar, camera) and other useful data (map, odometry) from your robot."}),"\n",(0,i.jsxs)(n.p,{children:["Open a new terminal inside the Docker container and run the following commands. You can reference the ",(0,i.jsx)(n.a,{href:"#docker-cheatsheet",children:"docker cheatsheet"})," at the top if needed:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Lists all currently available ROS2 topics"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 topic list\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/ros2_topic_list.png",alt:""})}),"\n",(0,i.jsxs)(n.ol,{start:"2",children:["\n",(0,i.jsx)(n.li,{children:"Reads topic data from the topic /echo (This is a LIDAR sensor)"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /scan # Ctrl + C to stop\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/ros2_topic_echo.png",alt:""})}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsx)(n.li,{children:"Get topic info and structure"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 topic info /scan\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/ros2_topic_info.png",alt:""})}),"\n",(0,i.jsx)(n.h4,{id:"publishing-to-a-topic",children:"Publishing to a Topic"}),"\n",(0,i.jsx)(n.p,{children:"There are two ways to publish data to a topic. You can set up a node via code to continuously or functionally send out data or you can use the command line to send out data. Here, we'll use the command line, and then we'll introduce nodes later on."}),"\n",(0,i.jsx)(n.h5,{id:"move-the-robot-via-cli-topic",children:"Move The Robot via CLI Topic"}),"\n",(0,i.jsx)(n.p,{children:"Try moving the robot by publishing to /cmd_vel:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'ros2 topic pub /cmd_vel geometry_msgs/msg/Twist "{linear: {x: 0.2}}"\n'})}),"\n",(0,i.jsx)(n.p,{children:"Stop the robot by setting it to 0:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'ros2 topic pub /cmd_vel geometry_msgs/msg/Twist "{linear: {x: 0.0}}"\n'})}),"\n",(0,i.jsx)(n.h4,{id:"exercise-2-publish-a-robot-to-rotate",children:"Exercise 2. Publish a Robot to Rotate"}),"\n",(0,i.jsx)(n.p,{children:"Publish a message via CLI to rotate around it's axis."}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:(0,i.jsx)("strong",{children:"Hint"})}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Check what message type ",(0,i.jsx)(n.code,{children:"/cmd_vel"})," and what you can send it."]}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.code,{children:"ros2 interface show <message_type>"})," to see what values you can send"]}),"\n"]})]}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:(0,i.jsx)("strong",{children:"Solution"})}),(0,i.jsx)(n.p,{children:"You can rotate the robot around the z-axis (yaw) using the following CLI command:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'ros2 topic pub /cmd_vel geometry_msgs/msg/Twist "{angular: {z: 0.5}}"\n'})})]}),"\n",(0,i.jsx)(n.h3,{id:"rviz-1",children:"RViz"}),"\n",(0,i.jsx)(n.p,{children:"RViz is a useful visualization tool that allows us to display data from ROS 2 topics. With these examples, you will learn how to do that."}),"\n",(0,i.jsx)(n.h4,{id:"subscribe-to-a-new-data-source",children:"Subscribe to a new data source:"}),"\n",(0,i.jsx)(n.p,{children:"The Andino robot is constantly sending images from the camera. We can see them using RViz:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:'Click "Add" button on the bottom left corner of RViz'}),"\n",(0,i.jsx)(n.li,{children:"Choose by topic."}),"\n",(0,i.jsxs)(n.li,{children:["Choose ",(0,i.jsx)(n.code,{children:"Camera"})," under the ",(0,i.jsx)(n.code,{children:"/image_raw"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/rviz_add_camera.png",alt:""})}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["Set overlay alpha to 1 to hide the artifacts on top of the image\n",(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/rviz_add_camera_2.png",alt:""})]})}),"\n",(0,i.jsx)(n.h3,{id:"transformation-frames-tfs",children:"Transformation Frames (TFs)"}),"\n",(0,i.jsx)(n.p,{children:'This is the core of robotics representation and is used in ROS2 to describe spatial relationships between different coordinate frames in a robotic system. In simpler words, each transform frame sits in a different position on a 3D axis with its own coordinate system. They sit at the center of the robot, at the center of sensors, at joints, and they are the "Map" and "Odometry" frames. You can think of it as one being the global and the other being local. When your robot moves, the global doesn\'t move, but your local frame does. Transform frames allow us to convert positions and orientations from one frame to another, and basically keep track of how each part of your robot moves in relation to the other parts of the robot. This is crucial for tasks like navigation, sensor fusion, and manipulation. If you don\'t understand it, it\'s fine as this is an upper division and graduate level concept.'}),"\n",(0,i.jsx)(n.p,{children:"The main component for handling transforms in ROS 2 is the tf2 library. It provides:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Coordinate Frames"}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Each sensor or part of a robot has its own coordinate frame (e.g., the robot's base, sensors, end effectors)."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Transformations"}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"These include translations (movement along axes) and rotations (changes in orientation) between frames."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"By using transforms, robots can effectively understand their position in the world and how their sensors and motors are located in relation to their body."}),"\n",(0,i.jsx)(n.p,{children:"The relationship between these coordinate frames is determined with tf-tree. It essentially tells with a tree-like structure what is the child-frame's position in relation to the parent frame."}),"\n",(0,i.jsx)(n.h4,{id:"commonly-used-coordinate-frames",children:"Commonly Used Coordinate Frames"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Frame"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"map"})}),(0,i.jsx)(n.td,{children:"Provides a global reference point for the robot's environment. It typically contains 2D coordinates representing the robot's position in a known map."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"odom"})}),(0,i.jsx)(n.td,{children:"Tracks the robot\u2019s position relative to its starting point using odometry. Subject to drift and cumulative error."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"base_footprint"})}),(0,i.jsx)(n.td,{children:"Represents the 2D projection of the robot's base on the ground, often used for navigation and path planning."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"base_link"})}),(0,i.jsx)(n.td,{children:"The origin of the robot's body frame, used to anchor other sensors and links."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"laser_link"})}),(0,i.jsx)(n.td,{children:"Specifies the location and orientation of the robot\u2019s laser scanner, essential for tasks like SLAM and obstacle detection."})]})]})]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/ros2_tf_frames.png",alt:""})}),"\n",(0,i.jsx)(n.h3,{id:"tfs-in-rviz",children:"TFs in RViz"}),"\n",(0,i.jsx)(n.p,{children:'When working with RViz, you will need to use the "Fixed Frame" to determine from which frame\'s perspective you are visualizing the data. This is an important feature to know about, as sometimes the data you are looking to visualize might not be available if you are visualizing a wrong frame (point of view).'}),"\n",(0,i.jsx)(n.h4,{id:"changing-fixed-frame",children:"Changing Fixed Frame"}),"\n",(0,i.jsx)(n.p,{children:'On Andino, the default frame is set to "base_footprint". This means that RViz coordinate origin (0, 0), is set to the robot\'s footprint. Move the robot around with teleoperation using Gazebo. You can see that the robot is always located in the center of the grid that RViz visualizes.'}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/rviz_coordinate_frame.png",alt:""})}),"\n",(0,i.jsx)(n.p,{children:'Try changing the "Fixed Frame" under "Global Options" from "base_footprint" to "odom" to use odometry as the coordinate frame instead of the robot base_footprint frame.'}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/rviz_fixed_frame.png",alt:""})}),"\n",(0,i.jsx)(n.p,{children:"Move the robot around and you'll see that the odometry is used as the coordinate frame instead of the robot base_footprint frame."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/rviz_odom_frame.png",alt:""})}),"\n",(0,i.jsx)(n.h4,{id:"visualizing-the-tf-tree",children:"Visualizing the TF-tree"}),"\n",(0,i.jsx)(n.p,{children:'Sometimes it might be useful to check the robot\'s tf-tree for debugging purposes. You can do it by opening the "Tree" option under the TF menu.'}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/1-ros_2_introduction/images/tf_tree.png",alt:""})}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsx)(n.p,{children:"To ensure the odom frame appears correctly at the top of the tree, you may need to press the reset button on the bottom left of Rviz. The odom frame tracks the robot's movement in the environment, making it the logical parent frame for accurately tracking the motion of all other frames."})}),"\n",(0,i.jsx)(n.h2,{id:"slam--navigation-demo",children:"SLAM & Navigation Demo"}),"\n",(0,i.jsxs)(n.p,{children:["Use ",(0,i.jsx)(n.code,{children:"slam-toolbox"})," to map your environment and ",(0,i.jsx)(n.code,{children:"Nav2"})," to navigate through it autonomously, while also learning how ROS 2 services work."]}),"\n",(0,i.jsx)(n.h4,{id:"what-youll-learn-2",children:"What You'll Learn"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Create a map using slam-toolbox"}),"\n",(0,i.jsx)(n.li,{children:"Navigate autonomously using Nav2"}),"\n",(0,i.jsx)(n.li,{children:"ROS 2 services"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"basic-concepts",children:"Basic Concepts"}),"\n",(0,i.jsx)(n.h4,{id:"slam-toolbox",children:"SLAM-toolbox"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://github.com/SteveMacenski/slam_toolbox/tree/ros2",children:"Slam-toolbox"})," is an advanced 2D SLAM (Simultaneous Localization and Mapping) solution for ROS 2. It provides tools for online (real-time) and offline mapping, lifelong mapping, loop closure, and localization. Slam-toolbox is designed for both real-time applications and mapping large-scale environments efficiently."]}),"\n",(0,i.jsx)(n.p,{children:'Simultaneous Localization and Mapping allows the robot to "localize" and map it\'s environment simultaneously. It tells us where the robot is and what the environment looks like based on sensor readings using some pretty neat mathematics.'}),"\n",(0,i.jsx)(n.h4,{id:"nav2",children:"Nav2"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://github.com/ros-navigation/navigation2",children:"Nav2"}),", or the Navigation2 stack, is a framework for ROS 2 that enables robots to navigate autonomously. It handles path planning, path following, obstacle avoidance, and localization in complex environments. Nav2 is modular, allowing developers to customize or replace components to suit specific robotic needs."]}),"\n",(0,i.jsx)(n.h4,{id:"amcl",children:"AMCL"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://github.com/ros-navigation/navigation2/tree/main/nav2_amcl",children:"AMCL"})," (Adaptive Monte Carlo Localization) is a probabilistic localization system used in ROS 2, and is part of the Nav2 stack. It enables robots to determine their position within a known map using particle filters. AMCL uses sensor data, typically from a LiDAR, to refine the estimated pose of the robot as it navigates."]}),"\n",(0,i.jsx)(n.h3,{id:"mapping-demo",children:"Mapping Demo"}),"\n",(0,i.jsx)(n.p,{children:"Let's try to map our simulator environment using the Andino."}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Run the simulation inside the docker container ",(0,i.jsx)(n.code,{children:"ros2 launch andino_gz andino_gz.launch.py"})]}),"\n",(0,i.jsxs)(n.li,{children:["Open a new terminal inside the container and run slam-toolbox ",(0,i.jsx)(n.code,{children:"ros2 launch andino_gz slam_toolbox_online_async.launch.py"})]}),"\n",(0,i.jsxs)(n.li,{children:["Subscribe to the ",(0,i.jsx)(n.code,{children:"/map"})," topic in RViz to view the map that is being built.\n",(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/2-slam_and_navigation_demo/images/subscribe_to_map_topic.png",alt:"map"})]}),"\n",(0,i.jsxs)(n.li,{children:["Use teleoperation in Gazebo to drive the robot around so you can get sensor readings.\n",(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/2-slam_and_navigation_demo/images/mapping_demo.png",alt:"localization"})]}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsx)(n.p,{children:'You can right-click the robot in simulation and choose "Follow" -camera mode to better keep track of your robot.'})}),"\n",(0,i.jsxs)(n.ol,{start:"5",children:["\n",(0,i.jsxs)(n.li,{children:["If you are satisfied with the map that was built, open a new terminal inside the docker container and run this command to save the map as a file ",(0,i.jsx)(n.code,{children:"ros2 run nav2_map_server map_saver_cli --free 0.15 --fmt png -f $HOME/andino_map"})]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"autonomous-navigation",children:"Autonomous Navigation"}),"\n",(0,i.jsxs)(n.p,{children:["Using the map we just built, we can autonomously navigate it using Nav2. Before continuing on though, make sure to stop the previous simulation and slam-toolbox by pressing ",(0,i.jsx)(n.code,{children:"CTRL+C"}),". Make sure to do this for all your terminals."]}),"\n",(0,i.jsx)(n.p,{children:"To autonomously navigate, follow these steps:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Open a new terminal inside the docker container and launch the Andino simulation with Nav2: ",(0,i.jsx)(n.code,{children:"ros2 launch andino_gz andino_gz.launch.py nav2:=True"})]}),"\n",(0,i.jsxs)(n.li,{children:["By default, it'll use a presaved map, but if you want to use the map we just created, run ",(0,i.jsx)(n.code,{children:' ros2 service call /map_server/load_map nav2_msgs/srv/LoadMap "{map_url: $HOME/andino_map.yaml}"'})]}),"\n",(0,i.jsxs)(n.li,{children:["In RViz, there'll be a ",(0,i.jsx)(n.code,{children:"2D Pose Estimate"})," for AMCL.\n",(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/2-slam_and_navigation_demo/images/pose_estimate.png",alt:"pose estimate"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["After pressing it, the robot will know it's location.\n",(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/2-slam_and_navigation_demo/images/nav2_demo_with_pose_estimate.png",alt:"location"})]}),"\n",(0,i.jsx)(n.h4,{id:"exercise-3-autonomous-navigation-with-nav2",children:"Exercise 3. Autonomous Navigation with Nav2"}),"\n",(0,i.jsx)(n.p,{children:"Give the robot different goals to get familiar with Nav2. Here are some guiding questions."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pay attention to what obstacles the robot is able to see with its laser scanner."}),"\n",(0,i.jsx)(n.li,{children:"Pay attention to the planned paths that the robot makes. Does it always follow them precisely?"}),"\n",(0,i.jsx)(n.li,{children:"Are the planned paths always feasible? Does the robot get stuck?"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"ros2-services",children:"ROS2 Services"}),"\n",(0,i.jsx)(n.p,{children:"If you changed Nav2 to use your 2D map, you might have noticed that you just called a ROS2 service. In addition to ROS2 topics, services are a complementary communication method. Instead of simply publishing and subscribing, services work using a request-response model."}),"\n",(0,i.jsxs)(n.p,{children:["Services can be called with a specific type of service request. The request is processed and a response received as a result. For example in the Nav2 demo, we called a /map_server/load_map service topic, to load a new map, with a request of ",(0,i.jsx)(n.code,{children:'"{map_url: /home/user/andino_map.yaml}"'}),", which has the type of nav2_msgs/srv/LoadMap message."]}),"\n",(0,i.jsxs)(n.p,{children:["To list all available services:\n",(0,i.jsx)(n.code,{children:"ros2 service list"})]}),"\n",(0,i.jsxs)(n.p,{children:["To include message type:\n",(0,i.jsx)(n.code,{children:"ros2 service list -t"})]}),"\n",(0,i.jsxs)(n.p,{children:["To invoke a request for a service:\n",(0,i.jsx)(n.code,{children:"ros2 service call <service_topic> <message_type> <request>"})]}),"\n",(0,i.jsx)(n.h2,{id:"create-your-first-ros-2-package",children:"Create Your First ROS 2 Package"}),"\n",(0,i.jsx)(n.p,{children:"Learn the structure of a ROS 2 package, how to build and source it, and how to write your own nodes. You'll be using the Turtle Nest GUI tool to create packages."}),"\n",(0,i.jsx)(n.h4,{id:"what-youll-learn-3",children:"What You'll Learn"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Create your first ROS 2 package"}),"\n",(0,i.jsx)(n.li,{children:"ROS 2 packages \u2013 how to create your own package"}),"\n",(0,i.jsx)(n.li,{children:"Building and sourcing"}),"\n",(0,i.jsx)(n.li,{children:"ROS 2 Nodes"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"creating-a-ros2-package",children:"Creating a ROS2 Package"}),"\n",(0,i.jsx)(n.p,{children:"ROS2 organizes codes via packages. If you're a python person, you can think of it as modules or a library, and if you're a C++ person, you can think of it as individual header files. As such, when building a decentralized codebase, you can simply integrate it into your system by adding a new package. This is extremely powerful but at the expense of overhead."}),"\n",(0,i.jsx)(n.p,{children:"Let's get started:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Launch the container and open a new terminal inside it."}),"\n",(0,i.jsxs)(n.li,{children:["Run the command ",(0,i.jsx)(n.code,{children:"turtle-nest"})," to bring up the GUI for ROS2 package creation."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Use these settings:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Package Name: ",(0,i.jsx)(n.code,{children:"ros2_exercises"})]}),"\n",(0,i.jsxs)(n.li,{children:["Destination: Path to exercises_ws, example ",(0,i.jsx)(n.code,{children:"/home/user/exercises_ws/src"})]}),"\n",(0,i.jsxs)(n.li,{children:["Package Type: ",(0,i.jsx)(n.code,{children:"Python"})," and uncheck the C++ option"]}),"\n",(0,i.jsxs)(n.li,{children:["Python Node Name: ",(0,i.jsx)(n.code,{children:"odometry_publisher"})]}),"\n",(0,i.jsxs)(n.li,{children:["Maintainer Name: ",(0,i.jsx)(n.code,{children:"your_name"})]}),"\n",(0,i.jsxs)(n.li,{children:["Package License: ",(0,i.jsx)(n.code,{children:"No license"})]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"All the other fields can be empty or unchecked as they're not needed for this section."}),"\n",(0,i.jsx)(n.h3,{id:"building-and-sourcing-a-package",children:"Building and Sourcing a Package"}),"\n",(0,i.jsxs)(n.p,{children:["In order for ROS2 to know that you created a new package, you must first build and source the dependencies. ROS2 uses the ",(0,i.jsx)(n.code,{children:"colcon"})," build system."]}),"\n",(0,i.jsxs)(n.p,{children:["First, navigate to your workspace:\n",(0,i.jsx)(n.code,{children:"cd /home/user/exercises_ws/"})]}),"\n",(0,i.jsxs)(n.p,{children:["Build the package via:\n",(0,i.jsx)(n.code,{children:"colcon build --symlink-install"})]}),"\n",(0,i.jsxs)(n.admonition,{type:"note",children:[(0,i.jsxs)(n.p,{children:["The above command builds all available packages but you can specify a ",(0,i.jsx)(n.code,{children:"--packages-select"})," flag to choose specific packages."]}),(0,i.jsx)(n.p,{children:"ALWAYS BE IN YOUR WORKSPACE WHEN BUILDING."})]}),"\n",(0,i.jsxs)(n.p,{children:["Source your workspace:\n",(0,i.jsx)(n.code,{children:"source install/setup.bash"})]}),"\n",(0,i.jsx)(n.p,{children:"This will build and source all the packages inside your exercises_ws -workspace. We use the --symlink-install to make our Python code symbolically linked, so that we don't have to rebuild every time we modify our code."}),"\n",(0,i.jsx)(n.admonition,{type:"danger",children:(0,i.jsx)(n.p,{children:"You need to do this build and source step every time you relaunch your Docker container!"})}),"\n",(0,i.jsxs)(n.p,{children:["After successfully building, you should see the following message. You can ignore the produced warning message.\n",(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/3-create_ros_2_package/images/build_warning.png",alt:"build"})]}),"\n",(0,i.jsx)(n.h3,{id:"details-of-ros2-package",children:"Details of ROS2 Package"}),"\n",(0,i.jsx)(n.p,{children:"We created our package in the exercises_ws folder. This folder is mounted inside our container in the volumes section of our docker-compose.yaml file, meaning that its contents are synced between our Ubuntu host and inside the Docker container at the $HOME/exercises_ws. All the code we write there will be automatically synchronized inside the container."}),"\n",(0,i.jsx)(n.p,{children:"Open the exercises_ws in your favorite IDE to take a closer look at what the new package contains. You can use any IDE you want or text editor."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/3-create_ros_2_package/images/package_structure.png",alt:"directories"})}),"\n",(0,i.jsx)(n.h4,{id:"ros2_exercises",children:"ros2_exercises"}),"\n",(0,i.jsx)(n.p,{children:"This is the root path of your package and serves as the base path for all of your code."}),"\n",(0,i.jsx)(n.h4,{id:"ros2_exercisesodometry_publisherpy",children:"ros2_exercises/odometry_publisher.py"}),"\n",(0,i.jsxs)(n.p,{children:["When creating a package, there'll be a folder named exactly after the package name and this is where you place all your source code for ROS2. For C++, it'll be ",(0,i.jsx)(n.code,{children:"src"})," folder. For this exercise, it created everything for us."]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:['It imports the necessary things, such as rclpy for writing ROS 2 Python code. A new Class OdometryPublisher is automatically created, that inherits a ROS 2 node to get access to features such as publishing and subscribing. In the main function, we initialize rclpy and the new node, as well as spin it in an infinite loop, which can be interrupted with CTRL-C. ROS 2 nodes "spin" to keep checking for new messages or requests so they can respond as soon as something happens.\n',(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/3-create_ros_2_package/images/odometry_node.png",alt:"details"})]})}),"\n",(0,i.jsx)(n.h4,{id:"setuppy",children:"setup.py"}),"\n",(0,i.jsx)(n.p,{children:"This is what holds all the necessary information for ROS2 system to know where your files are. It holds for example information about the existing nodes, the file path, launch files, and many more. If you add new Nodes for your package, you need to declare them here."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/3-create_ros_2_package/images/setup_py.png",alt:"setup.py"})}),"\n",(0,i.jsx)(n.h4,{id:"packagesxml",children:"packages.xml"}),"\n",(0,i.jsx)(n.p,{children:"This contains the metadata for your package, such as maintainer name and package description. Also, all the necessary package dependencies should be added here, such as existing core ROS packages or dependencies to your other ROS packages. The dependencies are what you use in your source code and are needed when building and running the code."}),"\n",(0,i.jsx)(n.h4,{id:"running-the-package",children:"Running the Package"}),"\n",(0,i.jsx)(n.p,{children:"Assuming you've built and sourced the package, it'll be available to run."}),"\n",(0,i.jsxs)(n.p,{children:["Run ",(0,i.jsx)(n.code,{children:"ros2 run ros2_exercises odometry_publisher"})," to run the package."]}),"\n",(0,i.jsxs)(n.p,{children:["You'll then get a message on your termianl from the ",(0,i.jsx)(n.code,{children:"OdometryPublisher"})," Node.\n",(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/3-create_ros_2_package/images/ros2_run.png",alt:"odometrypublisher"})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"robot-odometry",children:"Robot Odometry"}),"\n",(0,i.jsx)(n.p,{children:"Understand and implement robot odometry based on wheel velocities, and publish it using custom ROS 2 nodes in Python."}),"\n",(0,i.jsx)(n.h4,{id:"what-youll-learn-4",children:"What You'll Learn"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Calculate and publish your robot's odometry using wheel velocities"}),"\n",(0,i.jsx)(n.li,{children:"Robot odometry and how to calculate it"}),"\n",(0,i.jsx)(n.li,{children:"Publish and subscribe to topics from Python code"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Odometry is a technique used to estimate a robot\u2019s position and orientation over time. It is one of the essential things in mobile robotics, as good odometry data is often the foundation for localization, mapping and navigation. Problems in these features likely boil down to bad odometry data, which is why it is important to understand how odometry is calculated and the basic assumptions it relies on."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/4-robot_odometry/images/andino_odometry.png",alt:"odometry"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"How far Andino has travelled? We can answer this question by knowing how much each wheel has rotated and using this information to calculate the odometry."})}),"\n",(0,i.jsx)(n.h3,{id:"common-types-of-odometry-data",children:"Common Types of Odometry Data"}),"\n",(0,i.jsx)(n.p,{children:"Odometry can be estimated using data from the robot\u2019s sensors."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Wheel Odometry"}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Uses data from wheel encoders, or other types of sensors that can keep track of the position and measure the wheel rotations. By calculating how much each wheel has rotated, the robot can estimate how far it has moved."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Visual Odometry"}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Uses cameras or depth sensors to estimate movement by analyzing changes in images as the robot moves."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Inertial Odometry"}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Utilizes inertial measurement units (IMUs) that provide data on acceleration and rotational velocity to estimate position changes."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Sensor Fusion Odometry"}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Combines multiple sources (e.g., wheel encoders, IMUs, cameras) for more accurate and reliable odometry."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"exercise-calculate-odometry-from-wheel-encoders",children:"Exercise: Calculate Odometry from Wheel Encoders"}),"\n",(0,i.jsx)(n.p,{children:"In this practical exercise, we\u2019ll learn how to calculate odometry using data from simulated wheel encoders. In simulation, Andino uses Gazebo's built-in OdometryPublisher plugin to publish odometry data, but here we\u2019ll learn to do the same calculation ourselves using Python."}),"\n",(0,i.jsx)(n.p,{children:"Andino publishes the robot's left and right wheel positions and velocities on the /joint_states topic. We\u2019ll use this information to estimate the robot\u2019s position and velocity over time, just as you would on a real robot."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/4-robot_odometry/images/joint_states.png",alt:"topic data"})}),"\n",(0,i.jsxs)(n.p,{children:["Copy paste the code below into the ",(0,i.jsx)(n.code,{children:"OdometryPublisher"})," node found in ",(0,i.jsx)(n.code,{children:"odometry_publisher.py"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-py",children:"#!/usr/bin/env python3\nimport math\nimport matplotlib.pyplot as plt\n\nimport rclpy\nfrom rclpy.node import Node\nfrom tf_transformations import quaternion_from_euler\n\nfrom geometry_msgs.msg import Quaternion\nfrom nav_msgs.msg import Odometry\nfrom sensor_msgs.msg import JointState\n\n\nclass OdometryPublisher(Node):\n\n    def __init__(self):\n        super().__init__(\"odometry_publisher\")\n        # Use these wheel parameters for odometry calculation on Andino\n        self.wheel_separation = 0.137\n        self.wheel_radius = 0.033\n\n        # Initializing the robot position and time for robot odometry calculation\n        self.x = 0.0  # Robot's position on x-axis\n        self.y = 0.0  # Robot's position on y-axis\n        self.theta = 0.0  # Robot's orientation angle\n        self.last_time = self.get_clock().now()\n\n        # TODO: Subscribe to /joint_states topic to listen to data from left and right wheels.\n        #  The message type is JointState and quality of service can be set to 10.\n        #  Use self.joint_states_callback as the subscription callback.\n\n        # TODO: Create odometry publisher. Message type is Odometry, topic can be set to\n        #  /robot_odometry (not to clash with the existing Andino odometry topic) and qos to 10.\n\n    def joint_states_callback(self, joint_states):\n        # TODO: Read left and right wheel velocities from the JointState message\n\n        # TODO: Get the elapsed time since last odometry calculation, delta time (dt), in seconds.\n        #  Save current time to self.last_time\n\n        # TODO: The wheel velocities we read from the joint_states message are angular\n        #  joint velocities (rad/s). Convert them to linear velocities for each wheel by multiplying\n        #  them with a wheel radius. Then calculate the robot's linear and angular velocities\n        #  with the following formulas:\n        #  linear velocity = (vel right + vel left) / 2.0\n        #  angular velocity = (vel right - vel left) / wheel separation\n\n        # TODO: Now that we know how much time has elapsed since the last calculation,\n        #  what was robot's previous orientation angle (theta) and with what speed the\n        #  robot has moved, we can calculate the new position for the robot. Find out how to\n        #  calculate this for x-axis, y-axis and robot's orientation theta, and\n        #  update the values in self.x, self.y and self.theta.\n\n        # TODO: Create new Odometry message and populate stamp and frame IDs. The parent frame\n        #  ID is \"odom\" and child frame ID is \"base_link\".\n\n        # TODO: Add the updated robot's position and orientation to the Odometry message. \n        # Be careful, the Odometry message accepts the orientation in Quaternion notation!\n\n        # TODO: Add the updated linear and angular velocities in the Odometry message\n\n        # TODO: Publish the odometry message\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    odometry_publisher = OdometryPublisher()\n\n    try:\n        rclpy.spin(odometry_publisher)\n    except KeyboardInterrupt:\n        pass\n\n    odometry_publisher.destroy_node()\n    rclpy.try_shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsxs)(n.p,{children:["and add these to ",(0,i.jsx)(n.code,{children:"OdometryPublisher"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-py",children:"self.path_visualizer = PathVisualizer() ## Inside init\nself.path_visualizer.visualize(odom_msg.pose.pose.position.x, odom_msg.pose.pose.position.y) ## At the end of joint_states_callback\n"})}),"\n",(0,i.jsx)(n.h3,{id:"testing-the-odometry",children:"Testing the Odometry"}),"\n",(0,i.jsx)(n.p,{children:"Drive the robot around in the simulation while visualizing the odometry data."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Does the odometry data correspond precisely the driven path?"}),"\n",(0,i.jsx)(n.li,{children:"Would the data be as precise on a real robot?"}),"\n",(0,i.jsx)(n.li,{children:"Are you able to find situations where according to odometry data the robot is moving, while in simulation it isn't. If so, what could you do to improve the odometry estimation?"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/4-robot_odometry/images/odometry_visualization.png",alt:"data"})}),"\n",(0,i.jsx)(n.h4,{id:"your-task",children:"Your Task"}),"\n",(0,i.jsx)(n.p,{children:"The Python code has different sections denoted with TODO-comments that you should complete."}),"\n",(0,i.jsx)(n.p,{children:"You are to fill in the missing code pieces."}),"\n",(0,i.jsxs)(n.p,{children:["To test your solution, run the Andino simulation in a new terminal:\n",(0,i.jsx)(n.code,{children:"ros2 launch andino_gz andino_gz.launch.py"})]}),"\n",(0,i.jsx)(n.p,{children:"Then run:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"colcon build --symlink-install\nsource install/setup.bash\n"})}),"\n",(0,i.jsxs)(n.p,{children:["You can then test via:\n",(0,i.jsx)(n.code,{children:"ros2 run ros2_exercises odometry_publisher --ros-args -p use_sim_time:=True"})]}),"\n",(0,i.jsx)(n.p,{children:"You can start and stop your node during development, without restarting the whole simulation. You also don't have to rebuild the package after every change you make, thanks to --symlink-install. Rebuild is only needed if you stop the whole Docker container."}),"\n",(0,i.jsxs)(n.admonition,{type:"info",children:[(0,i.jsx)(n.p,{children:"Between each of the steps, we recommend to print out the values and drive the robot in simulation to see how they are changing over time. This will give you a better understanding of the whole solution."}),(0,i.jsx)(n.p,{children:"For a better learning experience, we do not recommend using generative AI like ChatGPT to finish this task."}),(0,i.jsx)(n.p,{children:"You can find the solution to this exercise below, but try to first solve it by your own. Learning to code is most effective through the process of trial, error, and overcoming challenges."})]}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:(0,i.jsx)("strong",{children:"Solution"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-py",children:"#!/usr/bin/env python3\nimport math\nimport matplotlib.pyplot as plt\n\nimport rclpy\nfrom rclpy.node import Node\nfrom tf_transformations import quaternion_from_euler\n\nfrom geometry_msgs.msg import Quaternion\nfrom nav_msgs.msg import Odometry\nfrom sensor_msgs.msg import JointState\n\n\nclass OdometryPublisher(Node):\n\n    def __init__(self):\n        super().__init__(\"odometry_publisher\")\n        # Use these wheel parameters for odometry calculation on Andino\n        self.wheel_separation = 0.137\n        self.wheel_radius = 0.033\n\n        # Initializing the robot position and time for robot odometry calculation\n        self.x = 0.0  # Robot's position on x-axis\n        self.y = 0.0  # Robot's position on y-axis\n        self.theta = 0.0  # Robot's orientation angle\n        self.last_time = self.get_clock().now()\n\n        # Subscribe to /joint_states topic to listen to data from left and right wheels.\n        #  The message type is JointState and quality of service can be set to 10.\n        #  Use self.joint_states_callback as the subscription callback.\n        self.joint_subscription = self.create_subscription(\n            JointState, '/joint_states', self.joint_states_callback, 10\n        )\n\n        # Create odometry publisher. Message type is Odometry, topic can be set to\n        #  /robot_odometry (not to clash with the existing Andino odometry topic) and qos to 10.\n        self.odom_publisher = self.create_publisher(Odometry, \"/robot_odometry\", 10)\n\n        self.path_visualizer = PathVisualizer()\n\n    def joint_states_callback(self, joint_states):\n        # Read left and right wheel velocities from the JointState message\n        joint_names = joint_states.name\n        left_wheel_index = joint_names.index(\"left_wheel_joint\")\n        right_wheel_index = joint_names.index(\"right_wheel_joint\")\n        left_wheel_vel = joint_states.velocity[left_wheel_index]\n        right_wheel_vel = joint_states.velocity[right_wheel_index]\n\n        # Get the elapsed time since last odometry calculation, delta time (dt), in seconds.\n        #  Save current time to self.last_time\n        current_time = self.get_clock().now()\n        dt = (current_time - self.last_time).nanoseconds / 1e9\n        self.last_time = current_time\n\n        # The wheel velocities we read from the joint_states message are angular\n        #  joint velocities (rad/s). Convert them to linear velocities for each wheel by multiplying\n        #  them with a wheel radius. Then calculate the robot's linear and angular velocities\n        #  with the following formulas:\n        #  linear velocity = (vel right + vel left) / 2.0\n        #  angular velocity = (vel right - vel left) / wheel separation\n        v_left = left_wheel_vel * self.wheel_radius\n        v_right = right_wheel_vel * self.wheel_radius\n        linear_velocity = (v_right + v_left) / 2.0\n        angular_velocity = (v_right - v_left) / self.wheel_separation\n\n        # Now that we know how much time has elapsed since the last calculation,\n        #  what was robot's previous orientation angle (theta) and with what speed the\n        #  robot has moved, we can calculate the new position for the robot. Find out how to\n        #  calculate this for x-axis, y-axis and robot's orientation theta, and\n        #  update the values in self.x, self.y and self.theta.\n        delta_x = linear_velocity * math.cos(self.theta) * dt\n        delta_y = linear_velocity * math.sin(self.theta) * dt\n        delta_theta = angular_velocity * dt\n\n        self.x += delta_x\n        self.y += delta_y\n        self.theta += delta_theta\n\n        # Create new Odometry message and populate stamp and frame IDs. The parent frame\n        #  ID is \"odom\" and child frame ID is \"base_link\".\n        odom_msg = Odometry()\n        odom_msg.header.stamp = current_time.to_msg()\n        odom_msg.header.frame_id = \"odom\"\n        odom_msg.child_frame_id = \"base_link\"\n\n        # Add the updated robot's position and orientation to the Odometry message\n        # Be careful, the Odometry message accepts the orientation in Quaternion notation!\n        odom_msg.pose.pose.position.x = self.x\n        odom_msg.pose.pose.position.y = self.y\n        odom_msg.pose.pose.position.z = 0.0\n        odom_quat = quaternion_from_euler(0, 0, self.theta)\n        odom_msg.pose.pose.orientation = Quaternion(\n            x=odom_quat[0], y=odom_quat[1], z=odom_quat[2], w=odom_quat[3]\n        )\n\n        # Add the updated linear and angular velocities in the Odometry message\n        odom_msg.twist.twist.linear.x = linear_velocity\n        odom_msg.twist.twist.linear.y = 0.0\n        odom_msg.twist.twist.angular.z = angular_velocity\n\n        # Publish the odometry message\n        self.odom_publisher.publish(odom_msg)\n\n        self.path_visualizer.visualize(odom_msg.pose.pose.position.x, odom_msg.pose.pose.position.y)\n\n\nclass PathVisualizer:\n    def __init__(self):\n        plt.ion()\n        self.fig, self.ax = plt.subplots()\n\n        # Lock the aspect ratio and set equal scaling for x and y\n        self.ax.set_aspect('equal', adjustable='box')\n\n        self.path_x, self.path_y = [], []\n\n    def visualize(self, x, y):\n        # Store position history\n        self.path_x.append(x)\n        self.path_y.append(y)\n\n        # Plot path\n        self.ax.clear()\n        self.ax.plot(self.path_x, self.path_y, 'b-', label='Path')\n        self.ax.plot(x, y, 'ro', label='Current Position')  # Mark current position\n        self.ax.set_xlabel('X Position (m)')\n        self.ax.set_ylabel('Y Position (m)')\n        self.ax.set_title('Traversed Path')\n        self.ax.legend()\n        plt.draw()\n        plt.pause(0.001)  # Short pause to update plot\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    odometry_publisher = OdometryPublisher()\n\n    try:\n        rclpy.spin(odometry_publisher)\n    except KeyboardInterrupt:\n        pass\n\n    odometry_publisher.destroy_node()\n    rclpy.try_shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})})]}),"\n",(0,i.jsx)(n.h3,{id:"visualizing-the-driven-path",children:"Visualizing the Driven Path"}),"\n",(0,i.jsx)(n.p,{children:"Once you are done with your solution, you can visualize the calculated odometry by drawing the robot positions. This will help you to verify your solution and also get a better understanding how odometry data works, and what are the possible drawbacks of it."}),"\n",(0,i.jsx)(n.p,{children:"To visualize the driven path using matplotlib, add the following class to your code:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-py",children:"class PathVisualizer:\n    def __init__(self):\n        plt.ion()\n        self.fig, self.ax = plt.subplots()\n\n        # Lock the aspect ratio and set equal scaling for x and y\n        self.ax.set_aspect('equal', adjustable='box')\n\n        self.path_x, self.path_y = [], []\n\n    def visualize(self, x, y):\n        # Store position history\n        self.path_x.append(x)\n        self.path_y.append(y)\n\n        # Plot path\n        self.ax.clear()\n        self.ax.plot(self.path_x, self.path_y, 'b-', label='Path')\n        self.ax.plot(x, y, 'ro', label='Current Position')  # Mark current position\n        self.ax.set_xlabel('X Position (m)')\n        self.ax.set_ylabel('Y Position (m)')\n        self.ax.set_title('Traversed Path')\n        self.ax.legend()\n        plt.draw()\n        plt.pause(0.001)  # Short pause to update plot\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:["Add these two lines to your ",(0,i.jsx)(n.code,{children:"OdometryPublisher"})," Node:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-py",children:"self.path_visualizer = PathVisualizer() ## inside init\nself.path_visualizer.visualize(odom_msg.pose.pose.position.x, odom_msg.pose.pose.position.y) ## At the end of joint_states_callback\n"})}),"\n",(0,i.jsx)(n.h3,{id:"test-the-odometry",children:"Test the Odometry"}),"\n",(0,i.jsx)(n.p,{children:"Drive the robot around in the simulation while visualizing the odometry data."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Does the odometry data correspond precisely the driven path?"}),"\n",(0,i.jsx)(n.li,{children:"Would the data be as precise on a real robot?"}),"\n",(0,i.jsx)(n.li,{children:"Are you able to find situations where according to odometry data the robot is moving, while in simulation it isn't. If so, what could you do to improve the odometry estimation?"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/4-robot_odometry/images/odometry_visualization.png",alt:"data"})}),"\n",(0,i.jsx)(n.h2,{id:"path-planning",children:"Path Planning"}),"\n",(0,i.jsxs)(n.p,{children:["Explore motion planning with ",(0,i.jsx)(n.code,{children:"Nav2"}),", tune parameters, and implement basic custom path planners."]}),"\n",(0,i.jsx)(n.h4,{id:"what-youll-learn-5",children:"What You'll Learn"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Basic navigation concepts"}),"\n",(0,i.jsx)(n.li,{children:"Modify Nav2 parameters"}),"\n",(0,i.jsx)(n.li,{children:"Custom path planning using Nav2"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Path planning is a common problem in robotics that focuses on finding the best route for a robot to move from a start point to a goal, avoiding obstacles along the way. In ROS 2, this is typically achieved using the Nav2 stack, which combines sensor data, maps, and algorithms to calculate and execute paths dynamically. Path planning is a core concept for autonomous navigation, enabling robots to operate in complex environments."}),"\n",(0,i.jsx)(n.p,{children:'In this exercise, you will get an overview of what path planning is and how it is implemented in ROS 2. You will implement a "Hello World" of the path planning, by creating the simplest form of planner: the Straight Line Planner.'}),"\n",(0,i.jsx)(n.p,{children:"The Straight Line Planner will plan the path between two points, without considering any obstacles on the way. This will give you an understanding of how new path planning algorithms can be implemented using ROS 2, enabling you to take things further on your own."}),"\n",(0,i.jsx)(n.h3,{id:"basic-concepts-1",children:"Basic Concepts"}),"\n",(0,i.jsx)(n.h4,{id:"static-map",children:"Static Map"}),"\n",(0,i.jsx)(n.p,{children:"A 2D grid-based representation of the environment, where each cell is marked as free, occupied, or unknown. It is used for global navigation planning and obstacle avoidance."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/static_map.png",alt:"static"})}),"\n",(0,i.jsx)(n.h4,{id:"global-costmap",children:"Global Costmap"}),"\n",(0,i.jsx)(n.p,{children:"The global costmap represents the entire known environment, highlighting obstacles and free space. It helps the planner find a viable path at a high level."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/global_costmap.png",alt:"global"})}),"\n",(0,i.jsx)(n.h4,{id:"local-costmap",children:"Local Costmap"}),"\n",(0,i.jsx)(n.p,{children:"The local costmap focuses on the area immediately surrounding the robot. It dynamically updates with sensor data to handle unexpected obstacles and ensure safe navigation."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/local_costmap.png",alt:"local"})}),"\n",(0,i.jsx)(n.h4,{id:"path-planner",children:"Path Planner"}),"\n",(0,i.jsx)(n.p,{children:'The path planner computes a path from the robot\u2019s start point to its goal while considering the global costmap. In this exercise, you\'ll implement a basic straight-line planner to understand the fundamentals of path planning algorithms. The produced path is often referred to as the "Global Plan".'}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/global_plan.png",alt:"planner"})}),"\n",(0,i.jsx)(n.h4,{id:"controller",children:"Controller"}),"\n",(0,i.jsx)(n.p,{children:"The controller translates the planned path into low-level motion commands, such as velocity and direction, to guide the robot in real-time."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/local_plan.png",alt:"controller"})}),"\n",(0,i.jsx)(n.h4,{id:"behavior-trees",children:"Behavior Trees"}),"\n",(0,i.jsx)(n.p,{children:"Behavior trees define how the robot should react in different situations by structuring its actions and decisions hierarchically. They enable complex behaviors like re-planning when obstacles block the path."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/bt.png",alt:"bt"})}),"\n",(0,i.jsxs)(n.admonition,{type:"info",children:[(0,i.jsx)(n.p,{children:"By this point, we expect you to be familiar on how to start a Docker container using docker compose up, and how to open a new terminal inside it using exec. From now on in the instructions, we won't necessarily separately specify to run the commands, or to open new terminal inside the Docker container. All the commands are expected to be run inside the Docker, unless otherwise specified."}),(0,i.jsx)(n.p,{children:"Inside our robotics_essentials_ros2 container we have two ROS workspaces. In the exercises_ws we are adding our custom packages and code. In the ros2_ws we are keeping all of our external dependencies, like the andino_gz package."})]}),"\n",(0,i.jsx)(n.h3,{id:"building-our-path-planner",children:"Building our Path Planner"}),"\n",(0,i.jsx)(n.p,{children:"We'll be using Nav2 to accomplish this. As you have seen in previous demos, Nav2 has been integrated with Andino already. In general, it is simple to take Nav2 and set it up with an existing robot. Two main steps are needed to do this:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Launch file that brings up Nav2 stack"}),"\n",(0,i.jsx)(n.li,{children:"Parameter file that configures all the Nav2 parameters"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["To view the contents of the launch file:\n",(0,i.jsx)(n.code,{children:"cat $HOME/ros2_ws/src/andino_gz/andino_gz/launch/andino_gz.launch.py"})]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsx)(n.p,{children:"Note: we are now using ros2_ws instead of exercises_ws. You can find here external dependencies used for this course, such as andino_gz"})}),"\n",(0,i.jsxs)(n.p,{children:["Another way is to check the source code directly in the ",(0,i.jsx)(n.img,{src:"https://github.com/Ekumen-OS/andino_gz/blob/humble/andino_gz/launch/andino_gz.launch.py",alt:"Andino GitHub repository"}),". You can either check the code straight in your browser, or clone the package and open it in your favourite IDE."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/nav2_bringup.png",alt:"github repo"})}),"\n",(0,i.jsx)(n.p,{children:"This part invokes a Nav2 launch file called bringup_launch.py, that further starts all the nodes needed for navigation; planner, controller, behavior trees, etc."}),"\n",(0,i.jsxs)(n.p,{children:["To view the contents of the parameter file:\n",(0,i.jsx)(n.code,{children:"cat $HOME/ros2_ws/src/andino_gz/andino_gz/config/nav2_params.yaml"})]}),"\n",(0,i.jsx)(n.p,{children:"This file includes all the parameters that we pass for Nav2 nodes, for example for amcl, controller_server and planner_server. Take a moment to view what kind of parameters these Nodes take in."}),"\n",(0,i.jsx)(n.h4,{id:"straight-line-planner",children:"Straight Line Planner"}),"\n",(0,i.jsx)(n.p,{children:"Let's replace the existing path planner with our custom implementation."}),"\n",(0,i.jsxs)(n.p,{children:["Nav2, by default, supports adding new path planners by implementing a plugin with C++. To keep this course's programming language consistent, we are using Python instead. We have implemented for you a new C++ Nav2 plugin ",(0,i.jsx)(n.a,{href:"https://github.com/triton-droids/ros2_onboarding/blob/main/packages/custom_nav2_planner/src/custom_nav2_planner.cpp",children:"(take a look at it here)"})," that requests a new plan by calling a ROS 2 service. This approach allows us to implement our path planner in Python by simply creating a service that:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Waits for new service requests"}),"\n",(0,i.jsx)(n.li,{children:"Gets a robot's starting pose and goal pose in a service request"}),"\n",(0,i.jsx)(n.li,{children:"Responds with a plan"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"We also have access to the global costmap, which normally would be used for path planning to plan around the obstacles, but for simplicity we omit using it, and instead create a plan just between two points."}),"\n",(0,i.jsx)(n.p,{children:"With all this information available, we are ready to start calculating new paths for our robot."}),"\n",(0,i.jsxs)(n.p,{children:["If you are interested to check the original implementation of the Straight Line Planner in C++, you can find it from the ",(0,i.jsx)(n.a,{href:"https://docs.nav2.org/plugin_tutorials/docs/writing_new_nav2planner_plugin.html",children:"Nav2 documentation"}),"."]}),"\n",(0,i.jsx)(n.h4,{id:"change-the-planner",children:"Change the Planner"}),"\n",(0,i.jsx)(n.p,{children:"Let's get started by manually changing the planner for Andino in the Nav2 parameter file that is found inside the andino_gz package."}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Open Andino's parameter file with your favorite text editor. We will use nano as an example: ",(0,i.jsx)(n.code,{children:"nano $HOME/ros2_ws/src/andino_gz/andino_gz/config/nav2_params.yaml"})]}),"\n",(0,i.jsx)(n.li,{children:"Find the place where planner_server parameters are set. Comment out the existing planner_server parameters and replace them with the following:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'planner_server:\n ros__parameters:\n   plugins: ["GridBased"]\n   use_sim_time: True\n   GridBased:\n     plugin: "custom_nav2_planner/CustomPlanner"\n'})}),"\n",(0,i.jsxs)(n.p,{children:["It should look like below after. (This replaces the originally used NavfnPlanner with our ",(0,i.jsx)(n.a,{href:"https://github.com/triton-droids/ros2_onboarding/blob/main/packages/custom_nav2_planner/src/custom_nav2_planner.cpp",children:"CustomPlanner"})," implementation.)\n",(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/nav2_planner_params.png",alt:"params"})]}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsx)(n.li,{children:"Save the file"}),"\n",(0,i.jsx)(n.li,{children:"Build and source"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"cd $HOME/ros2_ws/\ncolcon build\nsource install/setup.bash\n"})}),"\n",(0,i.jsx)(n.admonition,{type:"danger",children:(0,i.jsx)(n.p,{children:"Note for Docker users! If you rebuild or remove your Docker container, these changes won't persist. In this case, you will have to run these steps to change the planner again!"})}),"\n",(0,i.jsx)(n.h4,{id:"verify-the-planner-has-changed",children:"Verify the planner has changed"}),"\n",(0,i.jsx)(n.p,{children:"To verify our planner has changed, follow these steps:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Launch the simulation ",(0,i.jsx)(n.code,{children:"ros2 launch andino_gz andino_gz.launch.py nav2:=True"})]}),"\n",(0,i.jsx)(n.li,{children:"Start the simulation, give a pose estimate for the robot, and try to give a Nav2 goal to autonomously navigate. You should see that your robot does not plan any path, since our custom Straight Line Planner is not yet implemented."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/no_plan.png",alt:"custom_planner"})}),"\n",(0,i.jsx)(n.p,{children:"You should also see a warning logger message"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/service_not_available.png",alt:"warning"})}),"\n",(0,i.jsx)(n.h5,{id:"interestingly-few-seconds-after-sending-the-goal-you-will-notice-that-your-robot-will-start-moving-a-little-why-is-that",children:"Interestingly, few seconds after sending the goal, you will notice that your robot will start moving a little. Why is that?"}),"\n",(0,i.jsx)(n.p,{children:"Nav2 has a behavior server running to have recovery behaviors if a plan could not be calculated. This is useful for example if the robot is stuck in a way that it is not possible to calculate the path, or the goal is not reachable. During recovery behaviors, the robot will for example try to spin and back up a little, to try to get unstuck."}),"\n",(0,i.jsx)(n.h3,{id:"creating-straight-line-planner",children:"Creating Straight Line Planner"}),"\n",(0,i.jsx)(n.p,{children:"To add our custom code for the new path planner, let's first create a new Python ROS 2 package. You can stop your simulation launch with CTRL+C and follow these steps"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Run Turtle Nest: ",(0,i.jsx)(n.code,{children:"turtle-nest"})]}),"\n",(0,i.jsx)(n.li,{children:"Create a new package with the following options:"}),"\n"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Package Name: ",(0,i.jsx)(n.code,{children:"path_planner_example"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Destination: ",(0,i.jsx)(n.code,{children:"/home/user/exercises_ws/src"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Note: ",(0,i.jsx)(n.code,{children:"exercises_ws"}),", not ros2_ws"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Package type: ",(0,i.jsx)(n.code,{children:"Python"}),", uncheck C++"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Python Node Name: ",(0,i.jsx)(n.code,{children:"path_planner_node"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["License: ",(0,i.jsx)(n.code,{children:"No License"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsx)(n.li,{children:"Once the package has been created, build and source it:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd $HOME/exercises_ws/\ncolcon build --symlink-install\nsource install/setup.bash\n"})}),"\n",(0,i.jsxs)(n.ol,{start:"4",children:["\n",(0,i.jsx)(n.li,{children:"Verify that everything went smoothly by running the node:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"ros2 run path_planner_example path_planner_node --ros-args -p use_sim_time:=True\n"})}),"\n",(0,i.jsx)(n.p,{children:"You should see a Hello World message from the node."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/hello_world.png",alt:"hello_world"})}),"\n",(0,i.jsx)(n.h4,{id:"implementation-of-straight-line-planner",children:"Implementation of Straight Line Planner"}),"\n",(0,i.jsx)(n.p,{children:"Now, it is time to start implementing the actual code for the planner."}),"\n",(0,i.jsx)(n.p,{children:"Open your Node in your favorite IDE. You will find it on your host machine, outside the container in $HOME/exercises_ws/src/path_planner_example/path_planner_example/path_planner_node.py."}),"\n",(0,i.jsx)(n.p,{children:"Use the code below as a starting template:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-py",children:'#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\n\nfrom nav_msgs.msg import Path\nfrom geometry_msgs.msg import PoseStamped\nfrom create_plan_msgs.srv import CreatePlan\nfrom nav2_simple_commander.robot_navigator import BasicNavigator\n\n\nclass PathPlannerNode(Node):\n\n    def __init__(self):\n        super().__init__("path_planner_node")\n        # self.basic_navigator = BasicNavigator()  # Can be uncommented to get Global Costmap in create_plan_cb\n\n        # Creating a new service "create_plan", which is called by our Nav2 C++ planner plugin\n        # to receive a plan from us.\n        self.srv = self.create_service(CreatePlan, \'create_plan\', self.create_plan_cb)\n\n    def create_plan_cb(self, request, response):\n        # Getting all the information to plan the path\n        goal_pose = request.goal\n        start_pose = request.start\n        time_now = self.get_clock().now().to_msg()\n        # global_costmap = self.basic_navigator.getGlobalCostmap()  # Can be uncommented to get Global CostMap\n\n        print("----")\n        print(f"Starting pose: ({start_pose.pose.position.x}, {start_pose.pose.position.y})")\n        print(f"Goal pose: ({goal_pose.pose.position.x}, {goal_pose.pose.position.y}))")\n\n        response.path = create_straight_plan(start_pose, goal_pose, time_now)\n        return response\n\ndef create_straight_plan(start, goal, time_now):\n    """ \n    Creates a straight plan between start and goal points.\n    Does not use the global costmap to plan around obstacles, as normal planners would.\n    """\n    path = Path()\n\n    # TODO Set the frame_id and stamp for the Path header. Use frame_id from the goal header,\n    #  and time_now for the current time.\n\n    # Let\'s create a straight plan between our start and goal poses.\n    # It is not enough if we provide only the start and end positions as a path.\n    # For controller to follow path correctly, we will need to provide also\n    # points along this straight path with small intervals. There is a function\n    # "interpolate_coordinates" implemented for you that does this. It only needs\n    # the coordinates in a tuple format, for example:\n    # interpolate_coordinates((0, 0), (0, 0.5))\n    # This will give you coordinates between these two points with 0.1 interval:\n    # [(0.0, 0.0), (0.0, 0.1), (0.0, 0.2), (0.0, 0.3), (0.0, 0.4), (0.0, 0.5)]\n    # TODO Interpolate the coordinates between start and goal positions\n    \n    # TODO Loop through these interpolated coordinates and create a new PoseStamped()\n    #  message for each of them. You can set the same stamp and frame_id as for the Path().\n    #  Finally, add all of these points into the path.poses -array.\n\n    return path\n\ndef interpolate_coordinates(start, end, increment=0.1):\n    """\n    Interpolate coordinates between two points with a fixed increment.\n    This method calculates the coordinates of the points on the straight-line path that we are computing.\n\n    Args:\n        start (tuple): Starting coordinate (x1, y1).\n        end (tuple): Ending coordinate (x2, y2).\n        increment (float): Distance between interpolated points.\n\n    Returns:\n        list: List of interpolated points as (x, y) tuples.\n    """\n    x1, y1 = start\n    x2, y2 = end\n\n    # Calculate total distance using the Euclidean formula\n    dx = x2 - x1\n    dy = y2 - y1\n    distance = (dx ** 2 + dy ** 2) ** 0.5\n\n    # Calculate the number of steps\n    num_steps = int(distance / increment)\n\n    # Generate interpolated points\n    points = []\n    for i in range(num_steps + 1):  # +1 to include the end point\n        t = i / num_steps  # Normalized step (0.0 to 1.0)\n        x = x1 + t * dx  # Linear interpolation for x\n        y = y1 + t * dy  # Linear interpolation for y\n        points.append((x, y))\n\n    return points\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    path_planner_node = PathPlannerNode()\n\n    try:\n        rclpy.spin(path_planner_node)\n    except KeyboardInterrupt:\n        pass\n\n    path_planner_node.destroy_node()\n    rclpy.try_shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(n.h4,{id:"your-task-1",children:"Your Task"}),"\n",(0,i.jsx)(n.p,{children:"Run the simulation in one terminal, and the new PathPlannerNode in another one with the following commands:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"ros2 launch andino_gz andino_gz.launch.py nav2:=True"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"ros2 run path_planner_example path_planner_node --ros-args -p use_sim_time:=True"})}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Start the simulation, give a pose estimation and a new Nav2 goal. You will see your node now printing start and goal positions with a certain interval. Nav2 keeps requesting replanning of the path periodically by default."}),"\n",(0,i.jsx)(n.p,{children:"Go through the main parts of code and read the comments to understand what is currently implemented. Start following TODO's to fill up the parts that are missing to produce a full path"}),"\n",(0,i.jsx)(n.p,{children:"The node consists of 3 main parts:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"create_plan_cb()"}),": This is our service callback. When Nav2 requests for a new path, this function will be called with a request containing the start position and goal position."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"create_straight_plan()"}),": This is our main function to do the path planning in, and the only place you need to modify. Without any changes, it returns an empty path."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"interpolate_coordinates"}),": This function calculates intermediate points on a line between start and goal positions, with a 0.1 meters interval by default. You do not need to fully understand the contents of this function, only the way how it can be used."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:(0,i.jsx)("strong",{children:"Solution"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-py",children:'#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\n\nfrom nav_msgs.msg import Path\nfrom geometry_msgs.msg import PoseStamped\nfrom create_plan_msgs.srv import CreatePlan\nfrom nav2_simple_commander.robot_navigator import BasicNavigator\n\n\nclass PathPlannerNode(Node):\n\n    def __init__(self):\n        super().__init__("path_planner_node")\n        # self.basic_navigator = BasicNavigator()  # Can be uncommented to get Global Costmap in create_plan_cb\n\n        # Creating a new service "create_plan", which is called by our Nav2 C++ planner plugin\n        # to receive a plan from us.\n        self.srv = self.create_service(CreatePlan, \'create_plan\', self.create_plan_cb)\n\n    def create_plan_cb(self, request, response):\n        # Getting all the information to plan the path\n        goal_pose = request.goal\n        start_pose = request.start\n        time_now = self.get_clock().now().to_msg()\n        # global_costmap = self.basic_navigator.getGlobalCostmap()  # Can be uncommented to get Global CostMap\n\n        response.path = create_straight_plan(start_pose, goal_pose, time_now)\n        return response\n\ndef create_straight_plan(start, goal, time_now):\n    """ \n    Creates a straight plan between start and goal points.\n    Does not use the global costmap to plan around obstacles, as normal planners would.\n    """\n    path = Path()\n\n    # Set the frame_id and stamp for the Path header. Use frame_id from the goal header,\n    #  and time_now for the current time.\n    path.header.frame_id = goal.header.frame_id\n    path.header.stamp = time_now\n\n    # Let\'s create a straight plan between our start and goal poses.\n    # It is not enough if we provide only the start and end positions as a path.\n    # For controller to follow path correctly, we will need to provide also\n    # points along this straight path with small intervals. There is a function\n    # "interpolate_coordinates" implemented for you that does this. It only needs\n    # the coordinates in a tuple format, for example:\n    # interpolate_coordinates((0, 0), (0, 0.5))\n    # This will give you coordinates between these two points with 0.1 interval:\n    # [(0.0, 0.0), (0.0, 0.1), (0.0, 0.2), (0.0, 0.3), (0.0, 0.4), (0.0, 0.5)]\n    # Interpolate the coordinates between start and goal positions\n    interpolated_coordinates = interpolate_coordinates(\n        (start.pose.position.x, start.pose.position.y),\n        (goal.pose.position.x, goal.pose.position.y),\n    )\n    \n    # Loop through these interpolated coordinates and create a new PoseStamped()\n    #  message for each of them. You can set the same stamp and frame_id as for the Path().\n    #  Finally, add all of these points into the path.poses -array.\n    for point in interpolated_coordinates:\n        pose = PoseStamped()\n        pose.pose.position.x = point[0]\n        pose.pose.position.y = point[1]\n        pose.header.stamp = time_now\n        pose.header.frame_id = goal.header.frame_id\n        path.poses.append(pose)\n\n    return path\n\ndef interpolate_coordinates(start, end, increment=0.1):\n    """\n    Interpolate coordinates between two points with a fixed increment.\n    This method calculates the coordinates of the points on the straight-line path that we are computing.\n    \n    Args:\n        start (tuple): Starting coordinate (x1, y1).\n        end (tuple): Ending coordinate (x2, y2).\n        increment (float): Distance between interpolated points.\n\n    Returns:\n        list: List of interpolated points as (x, y) tuples.\n    """\n    x1, y1 = start\n    x2, y2 = end\n\n    # Calculate total distance using the Euclidean formula\n    dx = x2 - x1\n    dy = y2 - y1\n    distance = (dx ** 2 + dy ** 2) ** 0.5\n\n    # Calculate the number of steps\n    num_steps = int(distance / increment)\n\n    # Generate interpolated points\n    points = []\n    for i in range(num_steps + 1):  # +1 to include the end point\n        t = i / num_steps  # Normalized step (0.0 to 1.0)\n        x = x1 + t * dx  # Linear interpolation for x\n        y = y1 + t * dy  # Linear interpolation for y\n        points.append((x, y))\n\n    return points\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    path_planner_node = PathPlannerNode()\n\n    try:\n        rclpy.spin(path_planner_node)\n    except KeyboardInterrupt:\n        pass\n\n    path_planner_node.destroy_node()\n    rclpy.try_shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n\n'})})]}),"\n",(0,i.jsx)(n.p,{children:"If it is correct, you should be able to create a straight path that the robot follows."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/straight_plan.png",alt:"sol"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://github.com/triton-droids/ros2_onboarding/raw/main/5-path_planning/images/straight_plan_through_obstacle.png",alt:"sol_2"})}),"\n",(0,i.jsxs)(n.admonition,{type:"info",children:[(0,i.jsx)(n.p,{children:"If you wish, you can try to improve the path planning by also using the global costmap to plan around obstacles in the environment. You can for example implement some of the popular path planning algorithms, such as Dijkstra or A*."}),(0,i.jsx)(n.p,{children:"Make sure that your path planning algorithm is fast and efficient. Otherwise the path planning might time out, if the path calculation takes for too long."}),(0,i.jsx)(n.p,{children:"Good luck!"})]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>r});var i=t(6540);const o={},s=i.createContext(o);function a(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);